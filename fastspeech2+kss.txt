#할 일
1. G2P와 토크나이저
2. MFA로 duration 뽑기
3. 그 외 환경세팅

#순서
1. 파이썬 3.8, kss 데이터셋(SVS Dataset 폴더에), FastSpeech2-master(ming24) 설치
2. demo, img 제외하고 전부 vscode로 옮기기(vscode에서만 수정하기)
3. dataset.py 수정
-211, 213줄 LJSpeech > KSS
-우선은 config에 KSS 폴더도 생성(LJSpeech 복붙)
4. config-yaml시리즈 수정
-model.yaml 막줄 KSS
-preprocess.yaml 첫줄 dataset : KSS
-train.yaml output 폴더 이름들 (2~4 줄) 다 KSS로 바꿈.
5. Dataset Path
-kss dataset fastspeech2 master 폴더에 풀고 vscode로 옮김
6. text/cleaners.py
-def none_clenars(text) 추가 "do nothing, return text"-
-collapse_whitespace만 추가
7. lexcion 다운로드?
-transcript v1.4. txt 다운로드, 폴더에 넣고 vscode KSS 폴더로 옮김 -> lexicon으로는 부적합(but lab들의 집합)
(https://www.kaggle.com/datasets/bryanpark/korean-single-speaker -speech-dataset)
-ko.txt 다운로드 -> lexicon으로는 부적합 (지난번 오류의 원인?)
(https://github.com/open-dict-data/ipa-dict/blob/master/data/ko.txt)
8. make_lab.py (by chatgpt)
-transcript v1.4에서 추출해내는 원리 / wav + lexicon 조합이 아닌, transcript로 뽑는게 맞다고 하심.
-ChatGPT Aid(FastSpeech2) 폴더에 저장해둠 -> vscode에도 업로드
-실행 :
cd FastSpeech2
python make_lab.py
9. preprocess.yaml 수정
-text cleaners(12) : "none_cleaners"
-language(13) : "kr"
-corpus_path: "./KSS"
-lexicon_path: "./lexicon"
-raw_path: "./KSS"
-preprocessed_path: "./KSS_aligned"
10. preprocessor/kss.py 만듦
-ljspeeech.py 복붙
-speaker(17) : "KSS"
-with open : "metadata.csv" -> "transcript.v.1.4.txt"
11. prepare_align.py 수정
-14번째 줄 아래에 KSS 추가
-5번째 import 맨 뒤 KSS 추가, if "KSS" in config["dataset"]:, KSS.prepare_align(config)
12. clean_kss_labs.py
-clean_kss_labs.py 제작+ChatGPT AId 폴더 저장
-lab 파일 형식 잘못, 첫 한글 문장만 있어야 한다고 하는데 자모 분해, 영어&숫자 로그까지 같이 있었음.
13. mfa 직접해보기
13-0. 그 전에 prepare_align.py 부터 실행?
cd FastSpeech2
python prepare_align.py config/KSS/preprocess.yaml

13-1. mfa 설치
conda create -n mfa python=3.10 -y
conda activate mfa
conda install -c conda-forge montreal-forced-aligner

mfa model download acoustic korean_mfa
mfa model download dictionary korean_mfa

mfa model list acoustic
mfa model list dictionary

13-2. mfa 굴리기
pip install python-mecab-ko jamo
mfa model download g2p korean_mfa

# 1) validate: g2p 포함
mfa validate \
  /home/tts/rvc_project/FastSpeech2/KSS \
  korean_mfa \
  --g2p_model korean_mfa \
  #--clean

# 2) align: g2p 포함(영어도 섞여 있으면 아래 ‘혼종 텍스트’ 절 참고)
mfa align \
  /home/tts/rvc_project/FastSpeech2/KSS \
  korean_mfa \
  korean_mfa \
  /home/tts/rvc_project/FastSpeech2/KSS_aligned \
  #--clean --overwrite --g2p_model korean_mfa

14. textgrid가 몇개 없었음, partial_align.sh
# wav 개수/textgrid 개수
find KSS -type f -name "*.wav" | wc -l
find KSS_aligned -type f -name "*.TextGrid" | wc -l

#없는 TextGrid 목록
comm -23 \
  <(find KSS -type f -name "*.wav" -printf "%f\n" | sort) \
  <(find KSS_aligned -type f -name "*.TextGrid" -printf "%f\n" | sed 's/\.TextGrid$/.wav/' | sort)

#partial align
bash partial_align.sh

#workflow
-nogrid.txt 만들어서 gpt 폴더에 넣어둠.
-partial_align.sh 만들어서 gpt 폴더에 넣어둠.
-bash partial_align.sh
-nogrid에서 없는 textgrid 목록 뽑아와서 재생성
-kss partial에 nogrid의 wav, lab 복사함
-textgrid 뽑으면 partial aligned에 저장된 후 kss_align으로 복사.
-nogrid 갱신
-partial aligned 폴더 지우고 bash partial_align.sh로 재실행 이후 반복.

#원인 파악
라벨이 잘못 돼있었음.(같은말 반복)
+textgrid 출력됐는데도 틀린 라벨 있었음. 성능 안 좋으면 의심해볼것.

15. preprocessor 수정
...은 안하고 transcript 파일 그냥 밖으로 옮겨버림.
len pitch 문제 여전히...결국 if len(pitch) 부분 들여쓰기.
경로 중에 TextGrid가 들어간 부분 빼버림.

16. train.py 마지막 오류
get_vocoder에서 hifi-gan이면 ckpt 로드해야하는데 그게 엄슴
그래서 utils model 에서 hifigan vocoder 분기에서 elif 대신 else 써버림. ljspeech 아니면 전부 universial
universial generator tar.zip 압축해제 (cd 후 unzip)
utils/model.py 안에 있는 torch.load(...) 전부 map_location="cpu" 붙여줘.

17. 텐서 불일치 문제..
-modules.py : print들 추가로 길이 확인 > duration이 문제. [16, 60] 60이 문제.
-dataset.py : 추가 부분 넣어줘서(by gpt, 코드 내 추가 표시함) duration 자르기
> duration 뿐만 아니라 pitch, energy도 음운 단위로 길이 맞추는 작업 추가
> 변수 정의 및, 로그 길이 문제로 일부 print 삭제

18. 마지막 실행(의존성 설치, 전처리, 훈련까지, 이전버전, 틀린 실행 있음.)
cd FastSpeech2

# 1) 새 환경 만들기 (Python 3.8)
conda create -n fs2py38 python=3.8 -y
conda activate fs2py38

# 2) 기본 휠 도구 최신화
python -m pip install --upgrade pip setuptools wheel

# 3) PyTorch는 먼저 맞는 걸로 깔기 (CPU만 쓸거면 예시처럼)
pip install --index-url https://download.pytorch.org/whl/cpu torch==1.7.1+cpu

# 4) 나머지는 requirements에서 설치
pip install -r requirements.txt

# 가상환경(fs2py38) 활성화 상태에서
pip uninstall -y pyworld cython

# 구버전과 잘 맞는 Cython으로 고정
pip install "Cython==0.29.36" "numpy==1.19.0"

# 빌드 아이솔레이션 끄고 설치 (중요)
pip install --no-build-isolation --no-cache-dir "pyworld==0.2.10"

# 나머지 의존성은 그대로 진행
pip install -r requirements.txt --no-deps

pip install -r requirements.txt

#전처리
#python preprocess.py config/KSS/preprocess.yaml

# 1) protobuf를 3.20.x로 고정
python -m pip install --upgrade --force-reinstall "protobuf==3.20.3"

# 2) TensorBoard도 호환 버전으로 고정 (py3.8 안정 구간)
python -m pip install --upgrade --force-reinstall "tensorboard==2.11.2" "tensorboard-data-server<0.7" "grpcio<2.0.0"

# 3) 혹시 이상한 잔재 있으면 깔끔하게 재설치
python -m pip install --upgrade --force-reinstall "absl-py<2.0.0"

#훈련
#CUDA_VISIBLE_DEVICES="" \
#python train.py \
#-p config/KSS/preprocess.yaml \
#-m config/KSS/model.yaml \
-#t config/KSS/train.yaml

#오류 떠서 재실행...

python -m pip install --upgrade --force-reinstall "numpy==1.19.5"

python -m pip install --upgrade --force-reinstall "scipy==1.5.4" "scikit-learn==0.23.2"

python -m pip install --no-deps --force-reinstall "tensorboard==2.11.2"

python -m pip install --no-deps -r requirements.txt

#전처리
python preprocess.py config/KSS/preprocess.yaml

#훈련
CUDA_VISIBLE_DEVICES="" \
python train.py \
-p config/KSS/preprocess.yaml \
-m config/KSS/model.yaml \
-t config/KSS/train.yaml

19. wandb에서 학습 진행하기
pip install wandb
wandb login

#train.py
import부분에 import wandb
main() 시작 직후에
wandb.init(
    project="FastSpeech2-KSS",
    name="run_kss_fs2",
    config={
        "batch_size": train_config["optimizer"]["batch_size"],
        "learning_rate": train_config["optimizer"]["lr"],
        "pitch": preprocess_config["preprocessing"]["pitch"]["feature"],
        "energy": preprocess_config["preprocessing"]["energy"]["feature"],
    }
)
loss = total_loss.item() 부분을 찾은 후
wandb.log({
    "total_loss": total_loss.item(),
    "mel_loss": mel_loss.item(),
    "duration_loss": duration_loss.item(),
    "pitch_loss": pitch_loss.item(),
    "energy_loss": energy_loss.item(),
    "lr": current_learning_rate,
    "step": step
})

wandb 웹사이트 열어서 확인

20. 한번에 wandb 훈련(로그인은 해두기)
cd FastSpeech2

# 1) 새 환경 만들기 (Python 3.8)
conda create -n fs2py38 python=3.8 -y
conda activate fs2py38

# 2) 기본 휠 도구 최신화
python -m pip install --upgrade pip setuptools wheel

# 3) PyTorch는 먼저 맞는 걸로 깔기 (CPU만 쓸거면 예시처럼)
pip install --index-url https://download.pytorch.org/whl/cpu torch==1.7.1+cpu

# 4) 나머지는 requirements에서 설치
pip install -r requirements.txt

# 가상환경(fs2py38) 활성화 상태에서
pip uninstall -y pyworld cython

# 구버전과 잘 맞는 Cython으로 고정
pip install "Cython==0.29.36" "numpy==1.19.0"

# 빌드 아이솔레이션 끄고 설치 (중요)
pip install --no-build-isolation --no-cache-dir "pyworld==0.2.10"

# 나머지 의존성은 그대로 진행
pip install -r requirements.txt --no-deps

pip install -r requirements.txt

# 1) protobuf를 3.20.x로 고정
python -m pip install --upgrade --force-reinstall "protobuf==3.20.3"

# 2) TensorBoard도 호환 버전으로 고정 (py3.8 안정 구간)
python -m pip install --upgrade --force-reinstall "tensorboard==2.11.2" "tensorboard-data-server<0.7" "grpcio<2.0.0"

# 3) 혹시 이상한 잔재 있으면 깔끔하게 재설치
python -m pip install --upgrade --force-reinstall "absl-py<2.0.0"

#오류 떠서 재실행...

python -m pip install --upgrade --force-reinstall "numpy==1.19.5"

python -m pip install --upgrade --force-reinstall "scipy==1.5.4" "scikit-learn==0.23.2"

python -m pip install --no-deps --force-reinstall "tensorboard==2.11.2"

python -m pip install --no-deps -r requirements.txt

#전처리
#python preprocess.py config/KSS/preprocess.yaml

#wandb
pip install wandb
wandb login
pip install "pillow==9.5.0"

#훈련
CUDA_VISIBLE_DEVICES="" \
python train.py \
-p config/KSS/preprocess.yaml \
-m config/KSS/model.yaml \
-t config/KSS/train.yaml


21. 다시 훈련하려면?
cd FastSpeech2

# 1) 새 환경 만들기 (Python 3.8)
conda create -n fs2py38 python=3.8 -y
conda activate fs2py38

# 2) 기본 휠 도구 최신화
python -m pip install --upgrade pip setuptools wheel

# 3) PyTorch는 먼저 맞는 걸로 깔기 (CPU만 쓸거면 예시처럼)
pip install --index-url https://download.pytorch.org/whl/cpu torch==1.7.1+cpu

# 4) 나머지는 requirements에서 설치
pip install -r requirements.txt

# 가상환경(fs2py38) 활성화 상태에서
pip uninstall -y pyworld cython

# 구버전과 잘 맞는 Cython으로 고정
pip install "Cython==0.29.36" "numpy==1.19.0"

# 빌드 아이솔레이션 끄고 설치 (중요)
pip install --no-build-isolation --no-cache-dir "pyworld==0.2.10"

# 나머지 의존성은 그대로 진행
pip install -r requirements.txt --no-deps

pip install -r requirements.txt

# 1) protobuf를 3.20.x로 고정
python -m pip install --upgrade --force-reinstall "protobuf==3.20.3"

# 2) TensorBoard도 호환 버전으로 고정 (py3.8 안정 구간)
python -m pip install --upgrade --force-reinstall "tensorboard==2.11.2" "tensorboard-data-server<0.7" "grpcio<2.0.0"

# 3) 혹시 이상한 잔재 있으면 깔끔하게 재설치
python -m pip install --upgrade --force-reinstall "absl-py<2.0.0"

#오류 떠서 재실행...

python -m pip install --upgrade --force-reinstall "numpy==1.19.5"

python -m pip install --upgrade --force-reinstall "scipy==1.5.4" "scikit-learn==0.23.2"

python -m pip install --no-deps --force-reinstall "tensorboard==2.11.2"

python -m pip install --no-deps -r requirements.txt

#전처리
#python preprocess.py config/KSS/preprocess.yaml

#wandb
pip install wandb
wandb login
pip install "pillow==9.5.0"

#restore step으로 이어서 돌리기
CUDA_VISIBLE_DEVICES="" \
python train.py \
--restore_step 900000 \
-p config/KSS/preprocess.yaml \
-m config/KSS/model.yaml \
-t config/KSS/train.yaml

22. 들어보기
#훈련 멈춘 후 tensor보드에서
output > log > train, val 폴더 있음.
new terminal
conda activate fs2py38
pip install "google-auth<2,>=1.6.3"
tensorboard --logdir ./output/log/KSS --host 0.0.0.0 --port 6006

23. Tensor Board 해석
#Training/Reconstructed
-학습오디오 > 모델인코더/디코더 > 복원 mel > vocoder 음성 생성
-모델 예측x, 정답 mel 활용. 여기가 문제면 vocoder 문제.

#Training/Synthesized
-원래 텍스트만 넣고 모델이 멜스펙부터 끝까지 완전히 스스로 생성
-진짜 추론 품질과 거의 동일, 초기(50k까지)엔 발음, 유무성음 뒤틀림, 끊김 등

#Validation/Reconstructed
-검증셋의 mel을 넣고 재구성
-Training/Reconstructed 와 거의 동일

#Validatation/Synthesized
-검증 텍스트만으로 완전 추론
-테스트 환경과 가장 유사한 음성 품질

#23000 step 까지 훈련한 결과
-train/re, valide/re는 첨엔 그냥 원본인줄. 다행히 vocoder 문제는 없는 듯
-synthesized 전반적으로 아직 성능 별로.
-다만 50k(50000)까진 초기라 성능 별로라고도 하고, 앞부분은 어느 정도 학습이 된 부분도 있어서 선방한듯?
-전반적으로 몇개는 전부 끝이 아주 살짝 잘린? > fastspeech2에선 어느정도 흔한?
  -duration predictor가 문장 끝 길이를 약간 짧게 예측
  -vocoder가 silent frame을 fade out 처리?

#54000 step 까지 훈련한 결과
-어느정도 학습의 효과가 살짝은 있는 듯함.
-특히 train/synthesized에서 미약하지만 성능 향상을 느낄 수는 있었음.
-valid/synthesized에서도 buzzing sound 등이 조금은 줄었지만 초반 들리는 음성을 들어보
  뭔가 다른 문장을 학습한 것마냥, 발음이 부정확함.

#130000 step 까지 훈련한 결과
-성능 개선 확인됨. 그대로 훈련 더 진행하기로 결정.

from vscode_deleted_file_recovery import Recover
Recover.print_files(search_term=" tts@tts:~/rvc_project/FastSpeech2/output/ckpt/KSS") # Your desired search path

//////////////////////////////////////////////////////////////////////


15. duration npy 추출
: python prepare_align.py config/KSS/preprocess.yaml



#개념
alignment : 오디오, 텍스트 시간 축에 맞게 매칭 (wav+text -> 음소 시작/끝 정보(textgrid, duration)
G2P : 문자를 발음기호로 바꿈, alignment 전에 필수
duration : 
lab : 텍스트만 담긴 파일
WANDB?

//

1. 파이썬 3.8, KSS 데이터, FastSpeech2-master(ming24) 설치
2. KSS IAB+makeIAB(chatgpt), MFA(textgrid)
   align.ipynb(https://chldkato.tistory.com/195)
3. dataset.py 수정
-211, 213줄 LJSpeech > KSS
-우선은 config에 KSS 폴더도 생성(LJSpeech 복붙)
4. config-yaml시리즈 수정
-model.yaml 막줄 KSS
-preprocess.yaml dataset : KSS
-train.yaml output 폴더 이름들 다 KSS로 바꿈.
5. preprocess.yaml path
-IAB 파일들 wav 파일과 같이 놓기
-wav 파일 있는 곳으로 corpus path 설정
6. lexicon 문제
https://github.com/open-dict-data/ipa-dict/blob/master/data/ko.txt
> lexicon 대용으로 ko.txt 다운
> 파일명 korean_mfa.dict로 수정 후 위치시킴
> preprocess.yaml lexicon path 수정
> 혹시 몰라서 lexicon 폴더에도 복사
7. text_cleaners
-def none_clenars(text) 추가 "do nothing, return text"
-preprocess.yaml도 수정.(none_cleaners)
8. synthesize.py
-def preprocess_korean(Gpt 도움)
-elif kr 에서 preprocess_korean 실행되도록
-preprocess.yaml 언어 = kr
9. prepare_align.py 수정(KSS 분기 추가 등) GPT 도움
10. duration npy 추출
: python prepare_align.py config/KSS/preprocess.yaml

11. vscode 실행용으로 파일 경로 수정
12. kss raw data는 따로

13. 전처리 실행 : python preprocess.py config/KSS/preprocess.yaml

14. model.py else 분기 추가(ljspeech)

15. 훈련 실행 : CUDA_VISIBLE_DEVICES=0 \
python train.py \
-p config/KSS/preprocess.yaml \
-m config/KSS/model.yaml \
-t config/KSS/train.yaml

16. mfa 직접해보기
conda create -n mfa python=3.10 -y
conda activate mfa
conda install -c conda-forge montreal-forced-aligner

mfa model download acoustic korean_mfa
mfa model download dictionary korean_mfa
mfa model list  # 받아진 이름 확인용(정확한 키워드 확인)

mfa model list acoustic
mfa model list dictionary

mfa validate /home/tts/rvc_project/FastSpeech2/KSS_raw korean_mfa --clean
mfa align /home/tts/rvc_project/FastSpeech2/KSS_raw korean_mfa korean_mfa /home/tts/rvc_project/FastSpeech2/KSS_rawKSS_aligned --clean --overwrite

pip install python-mecab-ko jamo
(한 번 더 확실히 G2P 모델 받기(이미 받았어도 무해))
mfa model download g2p korean_mfa

(정렬 실행: G2P로 사전에 없는 단어 자동 발음 생성)
mfa align \
  /home/tts/rvc_project/FastSpeech2/KSS_raw \
  korean_mfa \
  korean_mfa \
  /home/tts/rvc_project/FastSpeech2/KSS_aligned \
  --clean --overwrite --g2p_model korean_mfa

17. preprocess yaml corpus path 수정(kss aligned 있는 쪽으로)
18. 재실행. (직접 만든 textgrid로 duration 추출)
: 10, 13

19. 
[파이썬 3.8 환경 -> requirements.txt 설치]
cd FastSpeech2

# 1) 새 환경 만들기 (Python 3.8)
conda create -n fs2py38 python=3.8 -y
conda activate fs2py38

# 2) 기본 휠 도구 최신화
python -m pip install --upgrade pip setuptools wheel

# 3) PyTorch는 먼저 맞는 걸로 깔기 (CPU만 쓸거면 예시처럼)
pip install --index-url https://download.pytorch.org/whl/cpu torch==1.7.1+cpu

# 4) 나머지는 requirements에서 설치
pip install -r requirements.txt

# 가상환경(fs2py38) 활성화 상태에서
pip uninstall -y pyworld cython

# 구버전과 잘 맞는 Cython으로 고정
pip install "Cython==0.29.36" "numpy==1.19.0"

# 빌드 아이솔레이션 끄고 설치 (중요)
pip install --no-build-isolation --no-cache-dir "pyworld==0.2.10"

# 나머지 의존성은 그대로 진행
pip install -r requirements.txt --no-deps

pip install -r requirements.txt

#전처리
python preprocess.py config/KSS/preprocess.yaml

# 1) protobuf를 3.20.x로 고정
python -m pip install --upgrade --force-reinstall "protobuf==3.20.3"

# 2) TensorBoard도 호환 버전으로 고정 (py3.8 안정 구간)
python -m pip install --upgrade --force-reinstall "tensorboard==2.11.2" "tensorboard-data-server<0.7" "grpcio<2.0.0"

# 3) 혹시 이상한 잔재 있으면 깔끔하게 재설치
python -m pip install --upgrade --force-reinstall "absl-py<2.0.0"

#훈련
CUDA_VISIBLE_DEVICES="" \
python train.py \
-p config/KSS/preprocess.yaml \
-m config/KSS/model.yaml \
-t config/KSS/train.yaml

20. train.py 수정
model = model.to(device) 

21. fastspeech2.py 수정
self.variance_adaptor = VarianceAdaptor(
    model_config,
    pitch_feature_level=preprocess_config["preprocessing"]["pitch"]["feature"],
    energy_feature_level=preprocess_config["preprocessing"]["energy"]["feature"],
)

22. modules.py 수정
(GPT 도움, vscode에서만 수정)

23. loss.py 수정

24. CPU 통일
-tools.py 등..

/// GPU가 시끄러워요 ///
who : 누가 연결했니?
안뜨면 sudo reboot

0.
-G2P : 그래프에서 음소로 변환하는 과정, 문자를 해당하는 소리로 변환
-Corpus : 말 뭉치
-https://linguisting.tistory.com/107

-? 모델은 yaml파일들을 어떻게 인식하는지
> yaml.load가 yaml 파일을 파이썬 객체로 만들어준다?
-? model.yaml speaker가 KSS는 지원 안되는거 같아보이던데
> 우선은 HifiGAN 보코더로 대충 써보고 소리가 별로면 별도 hifigan을 찾아보자.
-? 


